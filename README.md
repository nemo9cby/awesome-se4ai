# awesome-se4ai
A curated list of literature on se4ai

### Web Resources:

1. [Software Engineering for AI-Enabled Systems (SE4AI)](https://ckaestne.github.io/seai/S2020/) - CMU 17-445/645, Summer 2020.
2. [Introducing the Data Validation Tool](https://opensource.googleblog.com/2021/08/introducing-data-validation-tool.html) - Google. 2021.
3. [Datamations: Animated Explanations of Data Analysis Pipelines](http://jakehofman.com/publication/datamations/) - CHI 2021.
4. [Can AI Replace Lawyers? Researchers Say Machine Learning Can Help Predict Summary Judgment Outcomes](https://gadgets-ndtv-com.cdn.ampproject.org/v/s/gadgets.ndtv.com/apps/news/ai-artificial-intelligence-machine-learning-ml-replace-lawyers-software-predict-legal-summary-2507845?akamai-rum=off&amp=1&amp_gsa=1&amp_js_v=a6&usqp=mq331AQIKAGwASCAAgM%3D#amp_tf=From%20%251%24s&aoh=16287131304469&csi=1&referrer=https%3A%2F%2Fwww.google.com&ampshare=https%3A%2F%2Fgadgets.ndtv.com%2Fapps%2Fnews%2Fai-artificial-intelligence-machine-learning-ml-replace-lawyers-software-predict-legal-summary-2507845)
5. [Underspecification Presents Challenges in modern ML](https://www.youtube.com/watch?v=lGeUtmKCmKs)
6. [Assessment List for Trustworthy Artificial Intelligence (ALTAI) for self-assessment](https://digital-strategy.ec.europa.eu/en/library/assessment-list-trustworthy-artificial-intelligence-altai-self-assessment)
7. [The reusable holdout: Preserving validity in adaptive data analysis](https://ai.googleblog.com/2015/08/the-reusable-holdout-preserving.html)
8. [mllint — Linter for Machine Learning projects](https://github.com/bvobart/mllint)
9. [PE\_for\_ML](https://github.com/alvesisaque/PE_for_ML)
10. [Operationalizing Machine Learning](https://www.slideshare.net/databricks/operationalizing-machine-learningmanaging-provenance-from-raw-data-to-predictions-with-nabeel-sarwar)
11. [Versioning, Provenance, and Reproducibility in Production Machine Learning](https://ckaestne.medium.com/versioning-provenance-and-reproducibility-in-production-machine-learning-355c48665005)
12. [Time Travel and Provenance for Machine Learning Pipelines](https://www.usenix.org/conference/opml20/presentation/ormenisan)
13. [Automating Entity Matching Model Development](https://www.cs.sfu.ca/~jnwang/ppt/AutoML-EM-TR-Talk.pdf)
14. [DataPrep - The easiest way to
prepare data in Python](https://www.cs.sfu.ca/~jnwang/ppt/DataPrep-TR-Talk.pdf)
15. [Using PyTorch + NumPy? You're making a mistake.](https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/)
16. [MLOps: Continuous delivery and automation pipelines in machine learning](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)
17. [Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A Guide for Authors and Reviewers](https://pubs.rsna.org/doi/full/10.1148/ryai.2020200029)
18. [Versioning ML Models & Data in Time and Space](https://www.eecg.utoronto.ca/~shuruiz/paper/Dagstuhl19191-VersionControl4AI.pdf)
19. [Overton: A Data System for Monitoring and Improving Machine-Learned Products](https://machinelearning.apple.com/research/overton)
20. [Introducing Ludwig, a Code-Free Deep Learning Toolbox](https://eng.uber.com/introducing-ludwig/)
21. [Awesome-mlops](https://awesomeopensource.com/project/visenger/awesome-mlops)
22. [Git for data](https://youtu.be/r5uxntl_hWg)
23. [MLCommons](https://mlcommons.org/en/)
24. [Machine Learning at Industrial Scale: Lessons from the MLflow Project](https://youtube.com/watch?v=nCQ9WqXPIS4&feature=share)
25. [MediaPipe](https://github.com/google/mediapipe)
26. [Netflix's Metaflow: Reproducible machine learning pipelines](https://news.ycombinator.com/item?id=25497008)
27. [Traceability for Trustworthy AI: A Review of Models and Tools](https://www.mdpi.com/2504-2289/5/2/20)
28. [Finding duplicate images made easy!](https://github.com/idealo/imagededup)

### Papers:
1. [DeepXplore: Automated Whitebox Testing of Deep Learning Systems.](https://arxiv.org/pdf/1705.06640.pdf) 	Kexin Pei, Yinzhi Cao, Junfeng Yang, Suman Jana. SOSP 2017: 1-18.
2. [DeepTest: automated testing of deep-neural-network-driven autonomous cars.](https://arxiv.org/pdf/1708.08559.pdf) Yuchi Tian, Kexin Pei, Suman Jana, Baishakhi Ray. ICSE 2018: 303-314.
3. [CRADLE: cross-backend validation to detect and localize bugs in deep learning libraries.](https://www.cs.purdue.edu/homes/lintan/publications/cradle-icse19.pdf) Hung Viet Pham, Thibaud Lutellier, Weizhen Qi, Lin Tan. ICSE 2019: 1027-1038.
4. [Guiding deep learning system testing using surprise adequacy.](https://arxiv.org/pdf/1808.08444) Jinhan Kim, Robert Feldt, Shin Yoo. ICSE 2019: 1039-1049.
5. [Adversarial sample detection for deep neural network through model mutation testing.](https://arxiv.org/pdf/1812.05793) Jingyi Wang, Guoliang Dong, Jun Sun, Xinyu Wang, Peixin Zhang. ICSE 2019: 1245-1256.
6. [SLEMI: equivalence modulo input (EMI) based mutation of CPS models for finding compiler bugs in Simulink.](https://ranger.uta.edu/~csallner/papers/Chowdhury20SLEMI.pdf) Shafiul Azam Chowdhury, Sohil Lal Shrestha, Taylor T. Johnson, Christoph Csallner. ICSE 2020: 335-346.
7. [DeepBillboard: systematic physical-world testing of autonomous driving systems.](https://arxiv.org/pdf/1812.10812) Husheng Zhou, Wei Li, Zelun Kong, Junfeng Guo, Yuqun Zhang, Bei Yu, Lingming Zhang, Cong Liu. ICSE 2020: 347-358.
8. [Misbehaviour prediction for autonomous driving systems.](https://arxiv.org/pdf/1910.04443.pdf) Andrea Stocco, Michael Weiss, Marco Calzana, Paolo Tonella. ICSE 2020: 359-371.
9. [Approximation-refinement testing of compute-intensive cyber-physical models: an approach based on system identification.](https://arxiv.org/pdf/1910.02837.pdf) Claudio Menghi, Shiva Nejati, Lionel C. Briand, Yago Isasi Parache. ICSE 2020: 372-384.
10. [A comprehensive study of autonomous vehicle bugs.](https://www.ics.uci.edu/~alfchen/josh_icse20.pdf) Joshua Garcia, Yang Feng, Junjie Shen, Sumaya Almanee, Yuan Xia, Qi Alfred Chen. ICSE 2020: 385-396.
11. [Importance-driven deep learning system testing.](https://arxiv.org/pdf/2002.03433.pdf) Simos Gerasimou, Hasan Ferit Eniser, Alper Sen, Alper Cakan: ICSE 2020: 702-713
12. [ReluDiff: differential verification of deep neural networks.](https://arxiv.org/pdf/2001.03662.pdf) Brandon Paulsen, Jingbo Wang, Chao Wang. ICSE 2020:714-726
13. [Dissector: input validation for deep learning applications by crossing-layer dissection.](https://dl.acm.org/doi/10.1145/3377811.3380379) Huiyan Wang, Jingwei Xu, Chang Xu, Xiaoxing Ma, Jian Lu. ICSE 2020:727-738
14. [Towards characterizing adversarial defects of deep learning software from the lens of uncertainty.](https://arxiv.org/pdf/2004.11573) Xiyue Zhang, Xiaofei Xie, Lei Ma, Xiaoning Du, Qiang Hu, Yang Liu, Jianjun Zhao, Meng Sun. ICSE 2020:739-751
15. [White-box fairness testing through adversarial sampling.]() Peixin Zhang, Jingyi Wang, Jun Sun, Guoliang Dong, Xinyu Wang, Xingen Wang, Jin Song Dong, Ting Dai. ICSE 2020:949-960
16. [Structure-invariant testing for machine translation.](https://arxiv.org/pdf/1907.08710) Pinjia He, Clara Meister, Zhendong Su. ICSE 2020:961-973
17. [Automatic testing and improvement of machine translation.](https://arxiv.org/pdf/1910.02688) Zeyu Sun, Jie M. Zhang, Mark Harman, Mike Papadakis, Lu Zhang. ICSE 2020:974-985
18. [TRADER: trace divergence analysis and embedding regulation for debugging recurrent neural networks.](https://www.cs.purdue.edu/homes/taog/docs/ICSE20_Tao.pdf) Guanhong Tao, Shiqing Ma, Yingqi Liu, Qiuling Xu, Xiangyu Zhang.ICSE 2020:986-998
19. [Taxonomy of real faults in deep learning systems.](https://arxiv.org/abs/1910.11015) Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio, Andrea Stocco, Paolo Tonella. ICSE 2020:1110-1121
20. [Testing DNN image classifiers for confusion & bias errors.](https://arxiv.org/abs/1905.07831)Yuchi Tian, Ziyuan Zhong, Vicente Ordonez, Gail E. Kaiser, Baishakhi Ray. ICSE 2020:1122-1134
21. [Repairing deep neural networks: fix patterns and challenges.](https://arxiv.org/abs/2005.00972)Md Johirul Islam, Rangeet Pan, Giang Nguyen, Hridesh Rajan. ICSE 2020:1135-1146
22. [Fuzz testing based data augmentation to improve robustness of deep neural networks.](https://dl.acm.org/doi/10.1145/3377811.3380415)Xiang Gao, Ripon K. Saha, Mukul R. Prasad, Abhik Roychoudhury. ICSE 2020:1147-1158. [Video](https://www.youtube.com/watch?v=2VNL9yQnhp4).
23. [An empirical study on program failures of deep learning jobs.](https://hongyujohn.github.io/icse20-main-199.pdf) Ru Zhang, Wencong Xiao, Hongyu Zhang, Yu Liu, Haoxiang Lin, Mao Yang. ICSE 2020:1159-1170

***ICSE 2021***

24. [Are Machine Learning Cloud APIs Used Correctly?](http://people.cs.uchicago.edu/~cwan/paper/ml_api.pdf) Chengcheng Wan, Shicheng Liu, Henry Hoffmann, Michael Maire, Shan Lu. ICSE 2021:125-137.
25. [Resource-Guided Configuration Space Reduction for Deep Learning Models.](https://ieeexplore.ieee.org/document/9402095) Yanjie Gao, Yonghao Zhu, Hongyu Zhang, Haoxiang Lin, Mao Yang: ICSE 2021:175-187.
26. [Distribution-Aware Testing of Neural Networks Using Generative Models.](https://arxiv.org/abs/2102.13602) Swaroopa Dola, Matthew B. Dwyer, Mary Lou Soffa. ICSE 2021:226-237.
27. [An Empirical Study of Refactorings and Technical Debt in Machine Learning Systems.](https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=1723&context=hc_pubs) Yiming Tang, Raffi Khatchadourian, Mehdi Bagherzadeh, Rhia Singh, Ajani Stewart, Anita Raja. ICSE 2021: 238-250.
28. [DeepLocalize: Fault Localization for Deep Neural Networks.]() Mohammad Wardat, Wei Le, Hridesh Rajan. ICSE 2021:251-262
29. [DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural Payload Injection.]() Yuanchun Li, Jiayi Hua, Haoyu Wang, Chunyang Chen, Yunxin Liu. ICSE 2021: 263-274
30. [Reducing DNN Properties to Enable Falsification with Adversarial Attacks.]() David Shriver, Sebastian G. Elbaum, Matthew B. Dwyer. ICSE 2021: 275-287
31. [Graph-based Fuzz Testing for Deep Learning Inference Engines.]() Weisi Luo, Dong Chai, Xiaoyue Run, Jiang Wang, Chunrong Fang, Zhenyu Chen. ICSE 2021: 288-299
32. [RobOT: Robustness-Oriented Testing for Deep Learning Systems.]() Jingyi Wang, Jialuo Chen, Youcheng Sun, Xingjun Ma, Dongxia Wang, Jun Sun, Peng Cheng. ICSE 2021: 300-311
33. [Scalable Quantitative Verification For Deep Neural Networks.]() Teodora Baluta, Zheng Leong Chua, Kuldeep S. Meel, Prateek Saxena. ICSE 2021:312-323
34. [Operation is the hardest teacher: estimating DNN accuracy looking for mispredictions.]() Antonio Guerriero, Roberto Pietrantuono, Stefano Russo. ICSE 2021: 348-358
35. [AUTOTRAINER: An Automatic DNN Training Problem Detection and Repair System.]() Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Chao Shen. ICSE 2021: 359-371
36. [Self-Checking Deep Neural Networks in Deployment.]() Yan Xiao, Ivan Beschastnikh, David S. Rosenblum, Changsheng Sun, Sebastian G. Elbaum, Yun Lin, Jin Song Dong. ICSE 2021: 372-384
37. [Measuring Discrimination to Boost Comparative Testing for Multiple Deep Learning Models.]() Linghan Meng, Yanhui Li, Lin Chen, Zhi Wang, Di Wu, Yuming Zhou, Baowen Xu. ICSE 2021: 385-396
38. [Prioritizing Test Inputs for Deep Neural Networks via Mutation Analysis.]() Zan Wang, Hanmo You, Junjie Chen, Yingyi Zhang, Xuyuan Dong, Wenbin Zhang. ICSE 2021:397-409
39. [Testing Machine Translation via Referential Transparency.]() Pinjia He, Clara Meister, Zhendong Su. ICSE 2021: 410-422
40. [An Empirical Study on Deployment Faults of Deep Learning Based Mobile Applications.]() Zhenpeng Chen, Huihan Yao, Yiling Lou, Yanbin Cao, Yuanqiang Liu, Haoyu Wang, Xuanzhe Liu. ICSE 2021: 674-685
41. [White-Box Analysis over Machine Learning: Modeling Performance of Configurable Systems.]() Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel, Christian Kästner. ICSE 2021: 1072-1084

***FSE***

42. LAMP: data provenance for graph based machine learning algorithms through derivative computation. FSE 2017:786-797.

43. Shiqing Ma, Yingqi Liu, Wen-Chuan Lee, Xiangyu Zhang, Ananth Grama: MODE: automated neural network model debugging via state differential analysis and input selection. FSE 2018: 175-186

44. Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, Jianjun Zhao: DeepStellar: model-based quantitative analysis of stateful deep learning systems. FSE 2019: 477-487

45. Guy Barash, Eitan Farchi, Ilan Jayaraman, Orna Raz, Rachel Tzoref-Brill, Marcel Zalmanovici: Bridging the gap between ML solutions and their business requirements using feature interactions. FSE 2019:1048-1058

46. Sumon Biswas, Hridesh Rajan: Do the machine learning models on a crowd sourced platform exhibit bias? an empirical study on model fairness. FSE 2020:642-653

47. Joymallya Chakraborty, Suvodeep Majumder, Zhe Yu, Tim Menzies: Fairway: a way to build fair ML software. FSE 2020:654-665

48. Zhenpeng Chen, Yanbin Cao, Yuanqiang Liu, Haoyu Wang, Tao Xie, Xuanzhe Liu: A comprehensive study on challenges in deploying deep learning based software. 750-762

49. José Pablo Cambronero, Jürgen Cito, Martin C. Rinard: AMS: generating AutoML search spaces from weak specifications. 763-774

50. Shenao Yan, Guanhong Tao, Xuwei Liu, Juan Zhai, Shiqing Ma, Lei Xu, Xiangyu Zhang: Correlations between deep neural network model coverage criteria and model quality. 775-787

51. Zan Wang, Ming Yan, Junjie Chen, Shuang Liu, Dongdi Zhang: Deep learning library testing via effective model generation. 788-799

52. Fuyuan Zhang, Sankalan Pal Chowdhury, Maria Christakis: DeepSearch: a simple and effective blackbox attack for deep neural networks. 800-812

53.Yuhao Zhang, Luyao Ren, Liqian Chen, Yingfei Xiong, Shing-Chi Cheung, Tao Xie: Detecting numerical bugs in neural network architectures. 826-837

54. Ziqi Zhang, Yuanchun Li, Yao Guo, Xiangqun Chen, Yunxin Liu: Dynamic slicing for deep neural networks. 838-850

55. Fabrice Harel-Canada, Lingxiao Wang, Muhammad Ali Gulzar, Quanquan Gu, Miryung Kim: Is neuron coverage a meaningful measure for testing deep neural networks? 851-862

56. Shashij Gupta, Pinjia He, Clara Meister, Zhendong Su: Machine translation testing via pathological invariance. 863-875

57. Vincenzo Riccio, Paolo Tonella: Model-based exploration of the frontier of behaviours for deep learning system testing. 876-888

58.Rangeet Pan, Hridesh Rajan: On decomposing a deep neural network into modules. 889-900

59. Zenan Li, Xiaoxing Ma, Chang Xu, Jingwei Xu, Chun Cao, Jian Lu: Operational calibration: debugging confidence errors for DNNs in the field. 901-913

60. Zi Peng, Jinqiu Yang, Tse-Hsun (Peter) Chen, Lei Ma: A first look at the integration of machine learning models in complex autonomous driving systems: a case study on Apollo. 1240-1250

61. Yu Liu, Cheng Chen, Ru Zhang, Tingting Qin, Xiang Ji, Haoxiang Lin, Mao Yang: Enhancing the interoperability between deep learning frameworks by model conversion. 1320-1330

62. Yanjie Gao, Yu Liu, Hongyu Zhang, Zhengxian Li, Yonghao Zhu, Haoxiang Lin, Mao Yang: Estimating GPU memory consumption of deep learning models. 1342-1352

63. Jinhan Kim, Jeongil Ju, Robert Feldt, Shin Yoo: Reducing DNN labelling cost using surprise adequacy: an industrial case study for autonomous driving. 1466-1476

64. Joymallya Chakraborty, Suvodeep Majumder, Tim Menzies: Bias in machine learning software: why? how? what to do? FSE2021:429-440

65. Songqiang Chen, Shuo Jin, Xiaoyuan Xie: Validation on machine reading comprehension software without annotated labels: a property-based method. 590-602

66. Saikat Dutta, August Shi, Sasa Misailovic: FLEX: fixing flaky tests in machine learning projects by updating assertion bounds. 603-614

67. Ming Yan, Junjie Chen, Xiangyu Zhang, Lin Tan, Gan Wang, Zan Wang: Exposing numerical bugs in deep learning via gradient back-propagation. 627-638

68. Sahil Suneja, Yunhui Zheng, Yufan Zhuang, Jim Alain Laredo, Alessandro Morari: Probing model signal-awareness via prediction-preserving input minimization. 945-955

69. Shu Lin, Na Meng, Wenxin Li: Generating efficient solvers from constraint models. 956-967

70. Qingchao Shen, Haoyang Ma, Junjie Chen, Yongqiang Tian, Shing-Chi Cheung, Xiang Chen: A comprehensive study of deep learning compiler bugs. 968-980

71. Sumon Biswas, Hridesh Rajan: Fair preprocessing: towards understanding compositional fairness of data transformers in machine learning pipeline. 981-993

72. Max Hort, Jie M. Zhang, Federica Sarro, Mark Harman: Fairea: a model behaviour mutation approach to benchmarking bias mitigation methods. 994-1006

***ASE***

73. Sakshi Udeshi, Pryanshu Arora, Sudipta Chattopadhyay: Automated directed fairness testing. ASE 2018:98-108
74. Youcheng Sun, Min Wu, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska, Daniel Kroening:Concolic testing for deep neural networks. 109-119
75. Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chunyang Chen, Ting Su, Li Li, Yang Liu, Jianjun Zhao, Yadong Wang: DeepGauge: multi-granularity testing criteria for deep learning systems. 120-131
76. Mengshi Zhang, Yuqun Zhang, Lingming Zhang, Cong Liu, Sarfraz Khurshid: DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems. 132-142
77. Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang: AutoFocus: Interpreting Attention-Based Neural Networks by Code Perturbation. ASE 2019:38-41
78. Yan Zheng, Changjie Fan, Xiaofei Xie, Ting Su, Lei Ma, Jianye Hao, Zhaopeng Meng, Yang Liu, Ruimin Shen, Yingfeng Chen: Wuji: Automatic Online Combat Game Testing Using Evolutionary Deep Reinforcement Learning. 772-784
79. Mahdi Nejadgholi, Jinqiu Yang: A Study of Oracle Approximations in Testing Deep Learning Libraries. 785-796
80. [Property Inference for Deep Neural Networks.]() Divya Gopinath, Hayes Converse, Corina S. Pasareanu, Ankur Taly. ASE 2020: 797-809
81. [An Empirical Study Towards Characterizing Deep Learning Development and Deployment Across Different Frameworks and Platforms.]() Qianyu Guo, Sen Chen, Xiaofei Xie, Lei Ma, Qiang Hu, Hongtao Liu, Yang Liu, Jianjun Zhao, Xiaohong Li. ASE 2020: 810-822
82. [Audee: Automated Testing for Deep Learning Frameworks.]() Qianyu Guo, Xiaofei Xie, Yi Li, Xiaoyu Zhang, Yang Liu, Xiaohong Li, Chao Shen. ASE 2020:486-498
83. [Problems and Opportunities in Training Deep Learning Software Systems: An Analysis of Variance.]() Hung Viet Pham, Shangshu Qian, Jiannan Wang, Thibaud Lutellier, Jonathan Rosenthal, Lin Tan, Yaoliang Yu, Nachiappan Nagappan. ASE 2020: 771-783
84. [NEURODIFF: Scalable Differential Verification of Neural Networks using Fine-Grained Approximation.]() Brandon Paulsen, Jingbo Wang, Jiawei Wang, Chao Wang. ASE 2020: 784-796


***TOSEM***

85. [An Empirical Study of the Impact of Data Splitting Decisions on the Performance of AIOps Solutions.](https://dl.acm.org/doi/10.1145/3447876) Yingzhe Lyu, Heng Li, Mohammed Sayagh, Zhen Ming (Jack) Jiang, Ahmed E. Hassan. TOSEM 2021. 54:1-54:38
86. [Understanding Software-2.0: A Study of Machine Learning Library Usage and Evolution.](https://dl.acm.org/doi/abs/10.1145/3453478) Malinda Dilhara, Ameya Ketkar, Danny Dig. TOSEM 2021. 55:1-55:42
87. [Interpreting Deep Learning-based Vulnerability Detector Predictions Based on Heuristic Searching.](https://dl.acm.org/doi/10.1145/3429444) Deqing Zou, Yawei Zhu, Shouhuai Xu, Zhen Li, Hai Jin, Hengkai Ye. TOSEM 2021. 23:1-23:31
88. [Why an Android App Is Classified as Malware: Toward Malware Classification Interpretation.](https://arxiv.org/abs/2004.11516) Bozhi Wu, Sen Chen, Cuiyun Gao, Lingling Fan, Yang Liu, Weiping Wen, Michael R. Lyu. TOSEM 2021.21:1-21:29

***OTHERS***

89.	[Doing More with Less: Characterizing Dataset Downsampling for AutoML.](http://vldb.org/pvldb/vol14/p2059-zogaj.pdf) Fatjon Zogaj, José Pablo Cambronero, Martin Rinard, Jürgen Cito. Proc. VLDB Endow. 14(11): 2059-2072 (2021)
90. [An Experience Report on Machine Learning Reproducibility: Guidance for Practitioners and TensorFlow Model Garden Contributors
](https://arxiv.org/pdf/2107.00821) Vishnu Banna, Akhil Chinnakotla, Zhengxin Yan, Anirudh Vegesana, Naveen Vivek, Kruthi Krishnappa, Wenxin Jiang, Yung-Hsiang Lu, George K. Thiruvathukal, James C. Davis.
91. [Provenance in Databases: Why, How, and Where](https://homepages.inf.ed.ac.uk/jcheney/publications/provdbsurvey.pdf)
92. [DataHub: Collaborative Data Science & Dataset Version Management at Scale](https://arxiv.org/pdf/1409.0798.pdf)
93. [Ensuring Dataset Quality for Machine Learning
Certification](https://arxiv.org/pdf/2011.01799.pdf)
94. [On the experiences of adopting automated data validation in an industrial machine learning project](https://arxiv.org/pdf/2103.04095.pdf)
95. [Asset Management in Machine Learning: A Survey](https://arxiv.org/pdf/2102.06919.pdf)
96. [MSR4ML: Reconstructing Artifact Traceability in Machine Learning Repositories.](https://ieeexplore.ieee.org/document/9426012/) Aquilas Tchanjou Njomou, Alexandra Johanne Bifona Africa, Bram Adams, Marios Fokaefs. SANER 2021: 536-540
97. [Unveiling the Mystery of API Evolution in Deep Learning Frameworks: A Case Study of Tensorflow 2.]() Zejun Zhang, Yanming Yang, Xin Xia, David Lo, Xiaoxue Ren, John C. Grundy. ICSE (SEIP) 2021: 238-247
98. [Underspecification Presents Challenges for Credibility in
Modern Machine Learning](https://arxiv.org/pdf/2011.03395.pdf)
99. [A Benchmark for Interpretability Methods in Deep Neural Networks]() Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, Been Kim. NeurIPS 2019: 9734-9745
100. [A Data Quality-Driven View of MLOps](https://arxiv.org/pdf/2102.07750.pdf)
101. [Production Machine Learning Pipelines: Empirical Analysis and Optimization Opportunities](https://arxiv.org/pdf/2103.16007.pdf)
102. [Exploring the Assessment List for Trustworthy AI in
the Context of Advanced Driver-Assistance Systems](https://arxiv.org/pdf/2103.09051.pdf)
103. [Automated end-to-end management of the modeling lifecycle in deep learning](https://link.springer.com/article/10.1007/s10664-020-09894-9?s=15)
104. [Practices for Engineering Trustworthy Machine Learning Applications](https://arxiv.org/pdf/2103.00964.pdf)
105. [How are Deep Learning Models Similar?: An Empirical Study on Clone Analysis of Deep Learning Software]()
106. [CleanML: A Study for Evaluating the Impact of Data Cleaning on ML Classification Tasks]() Peng Li, Xi Rao, Jennifer Blase, Yue Zhang, Xu Chu, Ce Zhang. ICDE 2021: 13-24
107. [Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale]()
108. [On the Co-evolution of ML Pipelines and Source Code - Empirical Study of DVC Projects]() Amine Barrak, Ellis E. Eghan, Bram Adams. SANER 2021: 422-433
109. [Model Assertions for Monitoring and Improving ML Models](https://arxiv.org/pdf/2003.01668) Daniel Kang, Deepti Raghavan, Peter Bailis, Matei Zaharia. MLSys 2020
110. [TOWARDS FEDERATED LEARNING AT SCALE: SYSTEM DESIGN](https://arxiv.org/abs/1902.01046)
111. [Quality Assurance for AI-based Systems: Overview and Challenges](https://arxiv.org/pdf/2102.05351.pdf)
112. [The Collective Knowledge project: making ML models more portable and reproducible with open APIs, reusable best practices and MLOps](https://arxiv.org/abs/2006.07161)
